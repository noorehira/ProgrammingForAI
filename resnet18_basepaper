{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkZNJkLCd4mBXkC9rLOxIm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noorehira/ProgrammingForAI/blob/main/resnet18_basepaper\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9m6G3CiWzRl"
      },
      "outputs": [],
      "source": [
        "!pip install torch-geometric scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "from torch_geometric.nn import GCNConv  # âœ… Import GCNConv properly\n",
        "from torch_geometric.data import Data as GeometricData\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n"
      ],
      "metadata": {
        "id": "tWGsHZlGW0tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_images(dir_path, output_file):\n",
        "    labels_list = []\n",
        "    images_list = []\n",
        "    dir_path = Path(dir_path)\n",
        "    for img_path in dir_path.glob('*.[Jj][Pp][Gg]'):\n",
        "        images_list.append(str(img_path))\n",
        "        filename = img_path.stem\n",
        "        match = re.search(r'A(\\d+)', filename)\n",
        "        if match:\n",
        "            label = int(match.group(1))\n",
        "            labels_list.append(label)\n",
        "        else:\n",
        "            print(f\"No valid age found in {filename}\")\n",
        "            continue\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        for img, label in zip(images_list, labels_list):\n",
        "            f.write(f\"{img} {label}\\n\")\n",
        "    print(f\"Annotations saved to {output_file}\")\n",
        "    return images_list, labels_list\n",
        "\n",
        "img_dir = \"/kaggle/input/fgnet-dataset/FGNET/images\"\n",
        "output_file = \"/kaggle/working/annotations.txt\"\n",
        "images_list, labels_list = process_images(img_dir, output_file)"
      ],
      "metadata": {
        "id": "IFp7gmA5W8gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomAgeDataset(Dataset):\n",
        "    def __init__(self, img_dir, annotations, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.annotations = annotations\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, age_label = self.annotations[idx]\n",
        "        img = Image.open(os.path.join(self.img_dir, img_path)).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, torch.tensor(age_label, dtype=torch.float32)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "def load_dataset(img_dir, annotation_file):\n",
        "    annotations = []\n",
        "    with open(annotation_file, 'r') as f:\n",
        "        for line in f:\n",
        "            name, age = line.strip().split()\n",
        "            annotations.append((name, float(age)))\n",
        "    return CustomAgeDataset(img_dir, annotations, transform)"
      ],
      "metadata": {
        "id": "UpB7NTvUXC1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_patches(img_tensor, patch_size=16):\n",
        "    C, H, W = img_tensor.shape\n",
        "    patches = []\n",
        "    coords = []\n",
        "    h_patches = H // patch_size\n",
        "    w_patches = W // patch_size\n",
        "    for i in range(h_patches):\n",
        "        for j in range(w_patches):\n",
        "            patch = img_tensor[:, i * patch_size:(i + 1) * patch_size, j * patch_size:(j + 1) * patch_size]\n",
        "            patches.append(patch)\n",
        "            coords.append((i, j))\n",
        "    return patches, coords"
      ],
      "metadata": {
        "id": "90AetP_oXGFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_knn_graph(features, k=5):\n",
        "    features = features.cpu().detach().numpy()\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(features)\n",
        "    _, indices = nbrs.kneighbors(features)\n",
        "    edges = [(i, j) for i in range(len(indices)) for j in indices[i] if i != j]\n",
        "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "    return edge_index"
      ],
      "metadata": {
        "id": "shKDJTeOXJ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_nodes(features, mask_ratio=0.3):\n",
        "    mask = (torch.rand(features.shape[0]) > mask_ratio).float().unsqueeze(1)\n",
        "    return features * mask  # Apply mask"
      ],
      "metadata": {
        "id": "3sFvbjEJXKet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnchorEncoder(nn.Module):\n",
        "    def __init__(self, output_dim=128):\n",
        "        super(AnchorEncoder, self).__init__()\n",
        "        base_model = models.resnet18(pretrained=True)\n",
        "        base_model.fc = nn.Identity()\n",
        "        self.base = base_model\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, output_dim)\n",
        "        )\n",
        "    def forward(self, img):\n",
        "        x = self.base(img)\n",
        "        return self.mlp(x)\n",
        "\n",
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, in_dim=128, hidden_dim=128, out_dim=128):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = torch.relu(self.conv1(x, edge_index))\n",
        "        x = torch.relu(self.conv2(x, edge_index))\n",
        "        return x\n",
        "\n",
        "class RegressionHead(nn.Module):\n",
        "    def __init__(self, input_dim=128):\n",
        "        super(RegressionHead, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "tDxOTXegXN-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultipleContrastiveLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.2, beta=0.5, omega1=1.0, omega2=1.0, omega3=1.0):\n",
        "        super(MultipleContrastiveLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.omega1 = omega1\n",
        "        self.omega2 = omega2\n",
        "        self.omega3 = omega3\n",
        "\n",
        "    def forward(self, anchor, positive, negative, neighbor_positive):\n",
        "        d_ap = (anchor - positive).pow(2).sum(1)\n",
        "        d_an = (anchor - negative).pow(2).sum(1)\n",
        "        d_np = (anchor - neighbor_positive).pow(2).sum(1)\n",
        "        L_N = F.relu(d_ap - d_an + self.alpha).mean()\n",
        "        L_M = F.relu(d_np - d_an + self.alpha).mean()\n",
        "        L_V = -(F.relu(d_ap - d_an + self.alpha + self.beta)).mean()\n",
        "        loss = self.omega1 * L_N + self.omega2 * L_M + self.omega3 * L_V\n",
        "        return loss"
      ],
      "metadata": {
        "id": "lb76H_L6XQNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model_anchor, model_gcn, regression_head, optimizer, dataloader, device, contrastive_loss):\n",
        "    model_anchor.train()\n",
        "    model_gcn.train()\n",
        "    regression_head.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for img, age in dataloader:\n",
        "        img, age = img.to(device), age.to(device).float().unsqueeze(1)\n",
        "        anchor = model_anchor(img)\n",
        "        positive, negative = anchor.clone(), anchor[torch.randperm(anchor.size(0))]\n",
        "        reg_pred = regression_head(anchor)\n",
        "        reg_loss = F.mse_loss(reg_pred, age)\n",
        "        loss = reg_loss + contrastive_loss(anchor, positive, negative, positive)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * img.size(0)\n",
        "\n",
        "    return total_loss / len(dataloader.dataset)\n",
        "\n",
        "\n",
        "def evaluate(model_anchor, regression_head, dataloader, device, tau=5):\n",
        "    model_anchor.eval()\n",
        "    regression_head.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img, age in dataloader:\n",
        "            img = img.to(device)\n",
        "            age = age.cpu().numpy()\n",
        "\n",
        "            # Predict ages\n",
        "            anchor = model_anchor(img)\n",
        "            predicted_age = regression_head(anchor).squeeze(1).cpu().numpy()\n",
        "\n",
        "            all_preds.extend(predicted_age)\n",
        "            all_labels.extend(age)\n",
        "\n",
        "    mae = mean_absolute_error(all_labels, all_preds)\n",
        "\n",
        "    # Compute CS(5)\n",
        "    abs_errors = np.abs(np.array(all_preds) - np.array(all_labels))\n",
        "    cs_tau = np.mean(abs_errors <= tau) * 100\n",
        "\n",
        "    return mae, cs_tau\n"
      ],
      "metadata": {
        "id": "NTnOZDg5XSR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset = load_dataset(img_dir, output_file)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=8, shuffle=False)\n",
        "\n",
        "# Initialize models\n",
        "model_anchor = AnchorEncoder(output_dim=128).to(device)\n",
        "model_gcn = GCNEncoder(in_dim=128, hidden_dim=128, out_dim=128).to(device)\n",
        "regression_head = RegressionHead(input_dim=128).to(device)\n",
        "contrastive_loss = MultipleContrastiveLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(\n",
        "    list(model_anchor.parameters()) +\n",
        "    list(model_gcn.parameters()) +\n",
        "    list(regression_head.parameters()),\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 60\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model_anchor, model_gcn, regression_head, optimizer, train_loader, device, contrastive_loss)\n",
        "    val_mae, val_cs = evaluate(model_anchor, regression_head, val_loader, device, tau=5)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}: Train Loss = {train_loss:.4f}, Val MAE = {val_mae:.4f}, CS(5) = {val_cs:.2f}%\")\n"
      ],
      "metadata": {
        "id": "J1H6Ffh6XU-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}