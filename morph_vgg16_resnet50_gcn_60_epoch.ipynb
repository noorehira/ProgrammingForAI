{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6280980,
          "sourceType": "datasetVersion",
          "datasetId": 3576052
        },
        {
          "sourceId": 12394848,
          "sourceType": "datasetVersion",
          "datasetId": 7816001
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "morph/vgg16/resnet50/gcn/60 epoch",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ecde2521d5f147a5baacf5a51aa021da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8b18fbfd10744ccb38238d948bf29cc"
            ],
            "layout": "IPY_MODEL_bd5c84c0ef8040fead4c9b00ef7613b8"
          }
        },
        "b788f2f6234b4d588f07b67bca39441d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f2a550eed5e4ed1a70f42fbe42e733a",
            "placeholder": "​",
            "style": "IPY_MODEL_368548cadfd349108062b365104fbb3a",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "989d56e73f5346f19921a1994ddb8049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_18fe4adaf233435da7adc2ebff881a08",
            "placeholder": "​",
            "style": "IPY_MODEL_53d0e85aa25045e89cf15da583d2cc4f",
            "value": "noorhira"
          }
        },
        "d5503f516626433288c326696104c5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bc711cd5956c4d78ac4f3a4514095732",
            "placeholder": "​",
            "style": "IPY_MODEL_70027930ef8946c992ddba64bcfa0f37",
            "value": ""
          }
        },
        "2f46af734d2e459cbd409c8b4adb3ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_cea4bf1b0591415889f5ac8ecc17c621",
            "style": "IPY_MODEL_d5de91450b1640d3905c12eda1504347",
            "tooltip": ""
          }
        },
        "691aa9014a48447e92dcf4925c1bdefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb39b7701ee84dc5957ebbfb303690b9",
            "placeholder": "​",
            "style": "IPY_MODEL_cc8c675a49da4232ac205490ef56f53b",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "bd5c84c0ef8040fead4c9b00ef7613b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "8f2a550eed5e4ed1a70f42fbe42e733a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "368548cadfd349108062b365104fbb3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18fe4adaf233435da7adc2ebff881a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53d0e85aa25045e89cf15da583d2cc4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc711cd5956c4d78ac4f3a4514095732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70027930ef8946c992ddba64bcfa0f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cea4bf1b0591415889f5ac8ecc17c621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5de91450b1640d3905c12eda1504347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "eb39b7701ee84dc5957ebbfb303690b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8c675a49da4232ac205490ef56f53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c56218ce4e54b479b393613bf6a2941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a641bfab5093402b824f023a1bbbc36c",
            "placeholder": "​",
            "style": "IPY_MODEL_7a03ca2bc62249aba0a1b01a07ddcd64",
            "value": "Connecting..."
          }
        },
        "a641bfab5093402b824f023a1bbbc36c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a03ca2bc62249aba0a1b01a07ddcd64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "626f6112782b4069a991ca4fa79374a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50cc9776f5534668ba0d02675fb92ffd",
            "placeholder": "​",
            "style": "IPY_MODEL_19a8fd47113b46b08a2efdea2841e59e",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "50cc9776f5534668ba0d02675fb92ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a8fd47113b46b08a2efdea2841e59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "979b141a503a43bbb9ec2ac3702a237c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8eb5e1c63b94dbf8c071691b10194c2",
            "placeholder": "​",
            "style": "IPY_MODEL_65454a720856422b9572025b437f1e48",
            "value": "Connecting..."
          }
        },
        "d8eb5e1c63b94dbf8c071691b10194c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65454a720856422b9572025b437f1e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8b18fbfd10744ccb38238d948bf29cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a9b585fb8eb4922978ef54db0b3d2d3",
            "placeholder": "​",
            "style": "IPY_MODEL_a291193961d54005b0fdb82a3f9e3d23",
            "value": "Both username and API key cannot be empty or whitespace"
          }
        },
        "4a9b585fb8eb4922978ef54db0b3d2d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a291193961d54005b0fdb82a3f9e3d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noorehira/ProgrammingForAI/blob/main/morph_vgg16_resnet50_gcn_60_epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "vqyR3S4LaFYs",
        "outputId": "022f63dc-ce54-4735-ba4c-eeb35c39c928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "ecde2521d5f147a5baacf5a51aa021da",
            "b788f2f6234b4d588f07b67bca39441d",
            "989d56e73f5346f19921a1994ddb8049",
            "d5503f516626433288c326696104c5c9",
            "2f46af734d2e459cbd409c8b4adb3ab0",
            "691aa9014a48447e92dcf4925c1bdefe",
            "bd5c84c0ef8040fead4c9b00ef7613b8",
            "8f2a550eed5e4ed1a70f42fbe42e733a",
            "368548cadfd349108062b365104fbb3a",
            "18fe4adaf233435da7adc2ebff881a08",
            "53d0e85aa25045e89cf15da583d2cc4f",
            "bc711cd5956c4d78ac4f3a4514095732",
            "70027930ef8946c992ddba64bcfa0f37",
            "cea4bf1b0591415889f5ac8ecc17c621",
            "d5de91450b1640d3905c12eda1504347",
            "eb39b7701ee84dc5957ebbfb303690b9",
            "cc8c675a49da4232ac205490ef56f53b",
            "0c56218ce4e54b479b393613bf6a2941",
            "a641bfab5093402b824f023a1bbbc36c",
            "7a03ca2bc62249aba0a1b01a07ddcd64",
            "626f6112782b4069a991ca4fa79374a5",
            "50cc9776f5534668ba0d02675fb92ffd",
            "19a8fd47113b46b08a2efdea2841e59e",
            "979b141a503a43bbb9ec2ac3702a237c",
            "d8eb5e1c63b94dbf8c071691b10194c2",
            "65454a720856422b9572025b437f1e48",
            "a8b18fbfd10744ccb38238d948bf29cc",
            "4a9b585fb8eb4922978ef54db0b3d2d3",
            "a291193961d54005b0fdb82a3f9e3d23"
          ]
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecde2521d5f147a5baacf5a51aa021da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "chiragsaipanuganti_morph_path = kagglehub.dataset_download('chiragsaipanuganti/morph')\n",
        "noorhira_data_deca_path = kagglehub.dataset_download('noorhira/data-deca')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "cd7sZ7oCaFYv",
        "outputId": "7416a59f-5516-4567-9e1e-0336103da2c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'morph' dataset.\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/noorhira/data-deca?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186M/186M [00:10<00:00, 18.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric scikit-learn"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:08:59.077654Z",
          "iopub.execute_input": "2025-09-23T14:08:59.078316Z",
          "iopub.status.idle": "2025-09-23T14:09:02.140912Z",
          "shell.execute_reply.started": "2025-09-23T14:08:59.078287Z",
          "shell.execute_reply": "2025-09-23T14:09:02.140185Z"
        },
        "id": "vE7teWzQaFYw",
        "outputId": "b99e66e1-e587-4be4-f0f1-0b4b249414cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yacs opencv-python kornia trimesh"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:02.14244Z",
          "iopub.execute_input": "2025-09-23T14:09:02.142663Z",
          "iopub.status.idle": "2025-09-23T14:09:05.24606Z",
          "shell.execute_reply.started": "2025-09-23T14:09:02.14264Z",
          "shell.execute_reply": "2025-09-23T14:09:05.245416Z"
        },
        "id": "-aKyENyWaFYx",
        "outputId": "ac319385-a022-4711-a6ac-2c884ac412e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-4.8.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from yacs) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia)\n",
            "  Downloading kornia_rs-0.1.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.1->kornia) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.1->kornia) (3.0.2)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.8.2-py3-none-any.whl (729 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m729.1/729.1 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yacs, trimesh, kornia_rs, kornia\n",
            "Successfully installed kornia-0.8.1 kornia_rs-0.1.9 trimesh-4.8.2 yacs-0.1.8\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chumpy\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:05.247223Z",
          "iopub.execute_input": "2025-09-23T14:09:05.247509Z",
          "iopub.status.idle": "2025-09-23T14:09:08.244453Z",
          "shell.execute_reply.started": "2025-09-23T14:09:05.247469Z",
          "shell.execute_reply": "2025-09-23T14:09:08.24372Z"
        },
        "id": "KdeGvfxvaFYy",
        "outputId": "8f65776e-c13f-4894-9eb2-ee50ba772114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chumpy\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from chumpy) (1.16.2)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from chumpy) (1.17.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy>=0.13.0->chumpy) (2.0.2)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58263 sha256=7b3a77fe5f8a371fa1e481499eb516e2d608c3e4424b7e7234c6babe8c8d5b73\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/b7/0e/6f56330e9077b8a6aad99bdb76981b07a7e8b3f056def662a6\n",
            "Successfully built chumpy\n",
            "Installing collected packages: chumpy\n",
            "Successfully installed chumpy-0.70\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Patch deprecated aliases back in (for chumpy)\n",
        "if not hasattr(np, 'bool'):\n",
        "    np.bool = bool\n",
        "if not hasattr(np, 'int'):\n",
        "    np.int = int\n",
        "if not hasattr(np, 'float'):\n",
        "    np.float = float\n",
        "if not hasattr(np, 'complex'):\n",
        "    np.complex = complex\n",
        "if not hasattr(np, 'object'):\n",
        "    np.object = object\n",
        "if not hasattr(np, 'str'):\n",
        "    np.str = str\n",
        "if not hasattr(np, 'long'):\n",
        "    np.long = int  # Python 3 only has int\n",
        "if not hasattr(np, 'unicode'):\n",
        "    np.unicode = str"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:08.246212Z",
          "iopub.execute_input": "2025-09-23T14:09:08.246449Z",
          "iopub.status.idle": "2025-09-23T14:09:08.251778Z",
          "shell.execute_reply.started": "2025-09-23T14:09:08.246425Z",
          "shell.execute_reply": "2025-09-23T14:09:08.251058Z"
        },
        "id": "AMPP4lL3aFYy",
        "outputId": "0b3fcbb6-adb3-4128-99cb-d9bf004b0208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2599526712.py:12: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, 'object'):\n",
            "/tmp/ipython-input-2599526712.py:14: FutureWarning: In the future `np.str` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, 'str'):\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Create a writable working directory in Colab\n",
        "writable_deca_path = '/content/DECA'\n",
        "\n",
        "# Copy DECA folder from the kagglehub download into /content\n",
        "shutil.copytree(os.path.join(noorhira_data_deca_path, 'DECA'),\n",
        "                writable_deca_path,\n",
        "                dirs_exist_ok=True)\n",
        "\n",
        "# Move into that directory\n",
        "os.chdir(writable_deca_path)\n",
        "\n",
        "print(\"✅ DECA copied and working directory set to:\", os.getcwd())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:08.2525Z",
          "iopub.execute_input": "2025-09-23T14:09:08.252696Z",
          "iopub.status.idle": "2025-09-23T14:09:13.815559Z",
          "shell.execute_reply.started": "2025-09-23T14:09:08.252681Z",
          "shell.execute_reply": "2025-09-23T14:09:13.814992Z"
        },
        "id": "BAhoaKIhaFYz",
        "outputId": "48041dcd-44fe-4015-b196-54295deb3b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'noorhira/kaggle/input/data-deca/DECA'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2108127582.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a writable working directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwritable_deca_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'noorhira/kaggle/working/DECA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'noorhira/kaggle/input/data-deca/DECA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwritable_deca_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs_exist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Move into that directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \"\"\"\n\u001b[1;32m    597\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shutil.copytree\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'noorhira/kaggle/input/data-deca/DECA'"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "deca_file = 'decalib/deca.py'\n",
        "\n",
        "# Read and patch the file to comment out the renderer setup\n",
        "with open(deca_file, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Comment out the renderer setup function\n",
        "with open(deca_file, 'w') as file:\n",
        "    for line in lines:\n",
        "        if 'self._setup_renderer' in line:\n",
        "            file.write('# ' + line)  # comment it\n",
        "        else:\n",
        "            file.write(line)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:13.81629Z",
          "iopub.execute_input": "2025-09-23T14:09:13.81651Z",
          "iopub.status.idle": "2025-09-23T14:09:13.821617Z",
          "shell.execute_reply.started": "2025-09-23T14:09:13.816487Z",
          "shell.execute_reply": "2025-09-23T14:09:13.82106Z"
        },
        "id": "qXNPuoFLaFYz",
        "outputId": "8b302aa1-723a-4584-a1c4-c4d9633653fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'decalib/deca.py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1888608631.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Read and patch the file to comment out the renderer setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeca_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'decalib/deca.py'"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "def _setup_renderer(self, model_cfg):\n",
        "    # Skipping renderer setup due to Kaggle limitations\n",
        "    self.render = None\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:13.822298Z",
          "iopub.execute_input": "2025-09-23T14:09:13.822489Z",
          "iopub.status.idle": "2025-09-23T14:09:13.837872Z",
          "shell.execute_reply.started": "2025-09-23T14:09:13.822474Z",
          "shell.execute_reply": "2025-09-23T14:09:13.837305Z"
        },
        "id": "XqeHQN52aFY0"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import types\n",
        "import os\n",
        "\n",
        "# Set DECA path (for Colab)\n",
        "deca_path = '/content/DECA'\n",
        "sys.path.append(deca_path)\n",
        "os.chdir(deca_path)\n",
        "\n",
        "# Patch renderer to skip PyTorch3D requirement\n",
        "from decalib import deca as deca_module\n",
        "\n",
        "def dummy_renderer(self, model_cfg):\n",
        "    self.render = None\n",
        "\n",
        "deca_module.DECA._setup_renderer = dummy_renderer\n",
        "\n",
        "# Fix inspect compatibility for chumpy\n",
        "import inspect\n",
        "if not hasattr(inspect, 'getargspec'):\n",
        "    inspect.getargspec = inspect.getfullargspec\n",
        "\n",
        "# Import DECA and config\n",
        "from decalib.deca import DECA\n",
        "from decalib.utils.config import cfg as deca_cfg\n",
        "\n",
        "# Configure DECA\n",
        "deca_cfg.model.flame_model_path = os.path.join(deca_path, 'data/generic_model.pkl')\n",
        "deca_cfg.model.use_tex = False  # disable texture to avoid missing .npz\n",
        "deca_cfg.model.face_mask_path = ''  # optional\n",
        "\n",
        "deca = DECA(config=deca_cfg)\n",
        "\n",
        "print(\"✅ DECA initialized successfully in:\", deca_path)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:13.838434Z",
          "iopub.execute_input": "2025-09-23T14:09:13.838639Z",
          "iopub.status.idle": "2025-09-23T14:09:24.868507Z",
          "shell.execute_reply.started": "2025-09-23T14:09:13.838624Z",
          "shell.execute_reply": "2025-09-23T14:09:24.86773Z"
        },
        "id": "0TqjmfKCaFY0",
        "outputId": "d89edd44-2f4d-433f-92e7-c17316968c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/working/DECA'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-895042345.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdeca_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/working/DECA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeca_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeca_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Patch renderer to skip PyTorch3D requirement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/DECA'"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_deca_3d_features_batch(img_tensor_batch, deca):\n",
        "    from torchvision.transforms import Resize, Normalize\n",
        "    resize = Resize((224, 224))\n",
        "    normalize = Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "\n",
        "    batch_size = img_tensor_batch.size(0)\n",
        "    img_batch = torch.stack([resize(img) for img in img_tensor_batch])\n",
        "    img_batch = normalize(img_batch).to(next(deca.parameters()).device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        codedict = deca.encode(img_batch)\n",
        "        shape_params = codedict['shape']  # [B, 100]\n",
        "        exp_params = codedict['exp']      # [B, 50]\n",
        "        combined = torch.cat([shape_params, exp_params], dim=1)  # [B, 150]\n",
        "\n",
        "    return combined\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:24.869317Z",
          "iopub.execute_input": "2025-09-23T14:09:24.86969Z",
          "iopub.status.idle": "2025-09-23T14:09:24.87518Z",
          "shell.execute_reply.started": "2025-09-23T14:09:24.869665Z",
          "shell.execute_reply": "2025-09-23T14:09:24.874408Z"
        },
        "id": "fDZxe-wmaFY0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== MORPH DATASET LOADER (SAVE ANNOTATIONS) ====================\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import re, random\n",
        "\n",
        "# Custom augmentation\n",
        "class CustomAugment:\n",
        "    def __call__(self, img):\n",
        "        import torchvision.transforms.functional as TF\n",
        "        import random\n",
        "        # Flip\n",
        "        if random.random() > 0.5:\n",
        "            img = TF.hflip(img)\n",
        "        # Rotation\n",
        "        angle = random.uniform(-15, 15)\n",
        "        img = TF.rotate(img, angle)\n",
        "        # Color jitter\n",
        "        color_jitter = transforms.ColorJitter(\n",
        "            brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1\n",
        "        )\n",
        "        img = color_jitter(img)\n",
        "        # Affine\n",
        "        scale_val = random.uniform(0.9, 1.1)\n",
        "        translate_x = random.uniform(-0.05, 0.05) * img.width\n",
        "        translate_y = random.uniform(-0.05, 0.05) * img.height\n",
        "        shear_val = random.uniform(-5, 5)\n",
        "        img = TF.affine(\n",
        "            img, angle=0,\n",
        "            translate=(translate_x, translate_y),\n",
        "            scale=scale_val, shear=shear_val,\n",
        "            interpolation=TF.InterpolationMode.BILINEAR\n",
        "        )\n",
        "        return img\n",
        "\n",
        "# Custom dataset\n",
        "class CustomAgeDataset(Dataset):\n",
        "    def __init__(self, annotations, transform=None, augment=None):\n",
        "        self.annotations = annotations\n",
        "        self.transform = transform\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, age_label = self.annotations[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.augment:\n",
        "            img = self.augment(img)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, torch.tensor(age_label, dtype=torch.float32)\n",
        "\n",
        "# Base preprocessing\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "augment_transform = CustomAugment()\n",
        "\n",
        "# Function to load MORPH dataset and save annotations\n",
        "def load_dataset(img_dir, output_file=\"morph_annotations.txt\", max_images=35000):\n",
        "    img_dir = Path(img_dir)\n",
        "    annotations = []\n",
        "\n",
        "    # Match extensions\n",
        "    for img_path in img_dir.glob(\"*.*\"):\n",
        "        if img_path.suffix.lower() not in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "            continue\n",
        "\n",
        "        filename = img_path.stem\n",
        "        # Extract age from pattern like \"M19\" or \"F43\"\n",
        "        match = re.search(r\"[MF](\\d+)\", filename)\n",
        "        if match:\n",
        "            age = int(match.group(1))\n",
        "            annotations.append((str(img_path), age))\n",
        "        # Extract age from last part of filename like \"00M19\" → 19\n",
        "    suffix = filename.split(\"_\")[-1]  # e.g., \"00M19\"\n",
        "    match = re.search(r\"(\\d+)$\", suffix)  # safer: capture ending digits\n",
        "    if match:\n",
        "        age = int(match.group(1))\n",
        "        annotations.append((str(img_path), age))\n",
        "\n",
        "\n",
        "    if len(annotations) == 0:\n",
        "        raise ValueError(f\"❌ No images found in {img_dir}. Check path or filename pattern.\")\n",
        "\n",
        "    # Shuffle and limit\n",
        "    random.shuffle(annotations)\n",
        "    annotations = annotations[:max_images]\n",
        "\n",
        "    # Save to output_file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        for path, age in annotations:\n",
        "            f.write(f\"{path} {age}\\n\")\n",
        "\n",
        "    print(f\"✅ Found total images: {len(annotations)}\")\n",
        "    print(f\"Sample:\", annotations[0])\n",
        "\n",
        "    # Split train/val\n",
        "    split_idx = int(0.8 * len(annotations))\n",
        "    train_annotations = annotations[:split_idx]\n",
        "    val_annotations = annotations[split_idx:]\n",
        "\n",
        "    print(f\"Train: {len(train_annotations)}, Val: {len(val_annotations)}\")\n",
        "\n",
        "    train_dataset = CustomAgeDataset(train_annotations, transform=base_transform, augment=augment_transform)\n",
        "    val_dataset = CustomAgeDataset(val_annotations, transform=base_transform, augment=None)\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "# Run loader\n",
        "img_dir = \"/kaggle/input/morph/Dataset/Images/Train\"\n",
        "output_file = \"morph_annotations.txt\"\n",
        "\n",
        "train_dataset, val_dataset = load_dataset(img_dir, output_file, max_images=35000)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:24.877542Z",
          "iopub.execute_input": "2025-09-23T14:09:24.877882Z",
          "iopub.status.idle": "2025-09-23T14:09:25.61868Z",
          "shell.execute_reply.started": "2025-09-23T14:09:24.877865Z",
          "shell.execute_reply": "2025-09-23T14:09:25.617915Z"
        },
        "id": "fOdK9kyHaFY1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Check first 10 annotations directly\n",
        "with open(\"morph_annotations.txt\", \"r\") as f:\n",
        "    lines = f.readlines()[:10]\n",
        "\n",
        "print(\"🔍 Sample Annotations:\")\n",
        "for line in lines:\n",
        "    path, age = line.strip().split()\n",
        "    print(f\"File: {Path(path).name} -> Age: {age}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:25.619481Z",
          "iopub.execute_input": "2025-09-23T14:09:25.620015Z",
          "iopub.status.idle": "2025-09-23T14:09:25.630066Z",
          "shell.execute_reply.started": "2025-09-23T14:09:25.619987Z",
          "shell.execute_reply": "2025-09-23T14:09:25.629498Z"
        },
        "id": "7Q8UfYWRaFY2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import re\n",
        "# from pathlib import Path\n",
        "\n",
        "# # Base dataset path\n",
        "# dir_path = Path(\"/kaggle/input/morph/Dataset/Images/Train\")\n",
        "\n",
        "# images_list, labels_list = [], []\n",
        "\n",
        "# # Iterate through all jpg/JPG files\n",
        "# for img_path in dir_path.glob(\"*.[jJ][pP][gG]\"):\n",
        "#     filename = img_path.stem  # e.g., '262858_00M19'\n",
        "#     try:\n",
        "#         # Extract age from last part like '00M19' → '19'\n",
        "#         suffix = filename.split(\"_\")[-1]  # e.g., '00M19'\n",
        "#         age_match = re.search(r\"(\\d+)$\", suffix)  # match ending digits\n",
        "#         if age_match:\n",
        "#             age = int(age_match.group(1))\n",
        "#             images_list.append(str(img_path))\n",
        "#             labels_list.append(age)\n",
        "#         else:\n",
        "#             print(f\"Skipping {filename} (could not extract age)\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "# print(f\"Found total images: {len(images_list)}\")\n",
        "# print(\"First 10 samples:\")\n",
        "# for i in range(min(10, len(images_list))):\n",
        "#     print((images_list[i], labels_list[i]))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:25.630749Z",
          "iopub.execute_input": "2025-09-23T14:09:25.631016Z",
          "iopub.status.idle": "2025-09-23T14:09:25.642533Z",
          "shell.execute_reply.started": "2025-09-23T14:09:25.630992Z",
          "shell.execute_reply": "2025-09-23T14:09:25.641877Z"
        },
        "id": "IfuRBZ1HaFY2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import NearestNeighbors\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:25.643138Z",
          "iopub.execute_input": "2025-09-23T14:09:25.643391Z",
          "iopub.status.idle": "2025-09-23T14:09:29.062233Z",
          "shell.execute_reply.started": "2025-09-23T14:09:25.643371Z",
          "shell.execute_reply": "2025-09-23T14:09:29.061662Z"
        },
        "id": "wxfikV5WaFY2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== MODEL ARCHITECTURE ENHANCEMENTS ====================\n",
        "def image_to_patches(img_tensor, patch_size=16):\n",
        "    C, H, W = img_tensor.shape\n",
        "    patches = []\n",
        "    coords = []\n",
        "    h_patches = H // patch_size\n",
        "    w_patches = W // patch_size\n",
        "    for i in range(h_patches):\n",
        "        for j in range(w_patches):\n",
        "            patch = img_tensor[:, i * patch_size:(i + 1) * patch_size, j * patch_size:(j + 1) * patch_size]\n",
        "            patches.append(patch)\n",
        "            coords.append((i, j))\n",
        "    return patches, coords\n",
        "\n",
        "def build_knn_graph(features, k=5):\n",
        "    features = features.cpu().detach().numpy()\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(features)\n",
        "    _, indices = nbrs.kneighbors(features)\n",
        "    edges = [(i, j) for i in range(len(indices)) for j in indices[i] if i != j]\n",
        "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "    return edge_index\n",
        "\n",
        "def mask_nodes(features, mask_ratio=0.3):\n",
        "    mask = (torch.rand(features.shape[0], device=features.device) > mask_ratio).float().unsqueeze(1)\n",
        "    return features * mask  # Apply mask\n",
        "\n",
        "\n",
        "class AnchorEncoder(nn.Module):\n",
        "    def __init__(self, output_dim=256):\n",
        "        super(AnchorEncoder, self).__init__()\n",
        "\n",
        "        # ResNet-50 backbone\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
        "        self.resnet_proj = nn.Sequential(\n",
        "            nn.Linear(2048, 256), nn.ReLU(), nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        # VGG16 backbone\n",
        "        self.vgg = models.vgg16(pretrained=True).features\n",
        "        self.vgg_avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.vgg_proj = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 7 * 7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        # DECA\n",
        "        self.deca = deca\n",
        "        self.deca_proj = nn.Sequential(\n",
        "            nn.Linear(150, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "\n",
        "        # Final fusion\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(256 + 256 + 128, output_dim),\n",
        "            nn.LayerNorm(output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        B = img.size(0)\n",
        "\n",
        "        # ResNet\n",
        "        res_feat = torch.flatten(self.resnet(img), 1)\n",
        "        res_feat = self.resnet_proj(res_feat)\n",
        "\n",
        "        # VGG16\n",
        "        vgg_feat = self.vgg(img)\n",
        "        vgg_feat = self.vgg_avgpool(vgg_feat)\n",
        "        vgg_feat = self.vgg_proj(vgg_feat)\n",
        "\n",
        "        # DECA\n",
        "        with torch.no_grad():\n",
        "            deca_feat = extract_deca_3d_features_batch(img, self.deca)\n",
        "        deca_feat = self.deca_proj(deca_feat)\n",
        "\n",
        "        combined = torch.cat([res_feat, vgg_feat, deca_feat], dim=1)\n",
        "        return self.fusion(combined)\n",
        "\n",
        "\n",
        "class RegressionHead(nn.Module):\n",
        "    def __init__(self, input_dim=256):\n",
        "        super(RegressionHead, self).__init__()\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.regressor(x)\n",
        "\n",
        "class GATLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout=0.2, alpha=0.2):\n",
        "        super(GATLayer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
        "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
        "        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        h = torch.mm(x, self.W)\n",
        "        N = h.size(0)\n",
        "\n",
        "        a_input = torch.cat([h[edge_index[0]], h[edge_index[1]]], dim=1)\n",
        "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(1))\n",
        "\n",
        "        attention = -9e15 * torch.ones(N, N, device=x.device)\n",
        "        attention[edge_index[0], edge_index[1]] = e\n",
        "        attention = F.softmax(attention, dim=1)\n",
        "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
        "\n",
        "        h_prime = torch.matmul(attention, h)\n",
        "        return F.elu(h_prime)\n",
        "\n",
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, in_dim=128, hidden_dim=256, out_dim=256):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
        "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
        "        self.ln2 = nn.LayerNorm(out_dim)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.ln1(self.conv1(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.ln2(self.conv2(x, edge_index)))\n",
        "        return x\n",
        "\n",
        "class PatchEncoder(nn.Module):\n",
        "    def __init__(self, output_dim=128):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((2, 2)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 2 * 2, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "class MultipleContrastiveLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.2, beta=0.3, omega1=1.0, omega2=1.0, omega3=0.5):\n",
        "        super(MultipleContrastiveLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.omega1 = omega1\n",
        "        self.omega2 = omega2\n",
        "        self.omega3 = omega3\n",
        "\n",
        "    def forward(self, anchor, positive, negative, neighbor_positive):\n",
        "        d_ap = F.cosine_similarity(anchor, positive, dim=1)\n",
        "        d_an = F.cosine_similarity(anchor, negative, dim=1)\n",
        "        d_np = F.cosine_similarity(anchor, neighbor_positive, dim=1)\n",
        "\n",
        "        L_N = F.relu(d_an - d_ap + self.alpha).mean()\n",
        "        L_M = F.relu(d_an - d_np + self.alpha).mean()\n",
        "        L_V = -(F.relu(d_ap - d_an + self.alpha + self.beta)).mean()\n",
        "\n",
        "        loss = self.omega1 * L_N + self.omega2 * L_M + self.omega3 * L_V\n",
        "        return loss\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:29.062963Z",
          "iopub.execute_input": "2025-09-23T14:09:29.063391Z",
          "iopub.status.idle": "2025-09-23T14:09:29.084055Z",
          "shell.execute_reply.started": "2025-09-23T14:09:29.063372Z",
          "shell.execute_reply": "2025-09-23T14:09:29.083354Z"
        },
        "id": "TVPxM7-5aFY3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== TRAINING UTILITIES ====================\n",
        "def evaluate(model_anchor, regression_head, dataloader, device, tau=5):\n",
        "    model_anchor.eval()\n",
        "    regression_head.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img, age in dataloader:\n",
        "            img = img.to(device)\n",
        "            age = age.cpu().numpy()\n",
        "\n",
        "            anchor = model_anchor(img)\n",
        "            predicted_age = regression_head(anchor).squeeze(1).cpu().numpy()\n",
        "\n",
        "            all_preds.extend(predicted_age)\n",
        "            all_labels.extend(age)\n",
        "\n",
        "    mae = mean_absolute_error(all_labels, all_preds)\n",
        "    abs_errors = np.abs(np.array(all_preds) - np.array(all_labels))\n",
        "    cs_tau = np.mean(abs_errors <= tau) * 100\n",
        "\n",
        "    return mae, cs_tau\n",
        "\n",
        "def train_epoch(model_anchor, patch_encoder, model_gcn, regression_head, optimizer, dataloader, device, contrastive_loss):\n",
        "    model_anchor.train()\n",
        "    patch_encoder.train()\n",
        "    model_gcn.train()\n",
        "    regression_head.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for img, age in dataloader:\n",
        "        img, age = img.to(device), age.to(device).float().unsqueeze(1)\n",
        "\n",
        "        anchors = []\n",
        "        positives = []\n",
        "        regression_losses = []\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Process entire batch at once\n",
        "        anchor = model_anchor(img)\n",
        "\n",
        "        # Process each image for graph construction\n",
        "        for img_tensor, age_val in zip(img, age):\n",
        "            with torch.no_grad():\n",
        "                x, edge_index = patch_graph_from_image(img_tensor, patch_encoder, patch_size=32, k=8)\n",
        "            h_positive = model_gcn(x, edge_index).mean(dim=0, keepdim=True)\n",
        "            positives.append(h_positive)\n",
        "\n",
        "        positive = torch.cat(positives, dim=0)\n",
        "        reg_pred = regression_head(anchor)\n",
        "        reg_loss = F.smooth_l1_loss(reg_pred, age)\n",
        "\n",
        "        # Create negative samples by shuffling the batch\n",
        "        negative = anchor[torch.randperm(anchor.size(0))]\n",
        "\n",
        "        # Normalize features for contrastive loss\n",
        "        anchor_norm = F.normalize(anchor, dim=1)\n",
        "        positive_norm = F.normalize(positive, dim=1)\n",
        "        negative_norm = F.normalize(negative, dim=1)\n",
        "\n",
        "        con_loss = contrastive_loss(anchor_norm, positive_norm, negative_norm, positive_norm)\n",
        "        loss = reg_loss + 0.2 * con_loss  # Reduced contrastive weight\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_anchor.parameters(), max_norm=1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(patch_encoder.parameters(), max_norm=1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(model_gcn.parameters(), max_norm=1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(regression_head.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * img.size(0)\n",
        "\n",
        "    return total_loss / len(dataloader.dataset)\n",
        "\n",
        "def patch_graph_from_image(img_tensor, patch_encoder, patch_size=32, k=8, deca=None, deca_proj=None):\n",
        "    patches, coords = image_to_patches(img_tensor, patch_size=patch_size)\n",
        "    patch_batch = torch.stack(patches).to(img_tensor.device)  # [N, C, H, W]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        patch_feats = patch_encoder(patch_batch)  # [N, D]\n",
        "\n",
        "        # === Add DECA features per image ===\n",
        "        if deca is not None and deca_proj is not None:\n",
        "            deca_feat = extract_deca_3d_features_batch(img_tensor.unsqueeze(0), deca).to(img_tensor.device)  # [1, 150]\n",
        "            deca_feat = deca_proj(deca_feat)  # [1, 128]\n",
        "            deca_feat = deca_feat.repeat(patch_feats.size(0), 1)  # [N, 128]\n",
        "            patch_feats = torch.cat([patch_feats, deca_feat], dim=1)  # [N, 128+128 = 256]\n",
        "\n",
        "    edge_index = build_knn_graph(patch_feats, k=k)\n",
        "    x_masked = mask_nodes(patch_feats, mask_ratio=0.2)\n",
        "    return x_masked.to(img_tensor.device), edge_index.to(img_tensor.device)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:29.085Z",
          "iopub.execute_input": "2025-09-23T14:09:29.085291Z",
          "iopub.status.idle": "2025-09-23T14:09:29.111525Z",
          "shell.execute_reply.started": "2025-09-23T14:09:29.08527Z",
          "shell.execute_reply": "2025-09-23T14:09:29.110806Z"
        },
        "id": "8nwA9fYQaFY3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:29.112372Z",
          "iopub.execute_input": "2025-09-23T14:09:29.113049Z",
          "iopub.status.idle": "2025-09-23T14:09:32.168282Z",
          "shell.execute_reply.started": "2025-09-23T14:09:29.113024Z",
          "shell.execute_reply": "2025-09-23T14:09:32.167504Z"
        },
        "id": "toZRZJa8aFY4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== MAIN TRAINING LOOP ====================\n",
        "import torch                          # ✅ MUST come first\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data as GeometricData\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from PIL import Image\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "import math\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_dataset, val_dataset = load_dataset(img_dir, output_file)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Initialize models\n",
        "model_anchor = AnchorEncoder(output_dim=256)\n",
        "model_anchor.deca = deca\n",
        "model_anchor = model_anchor.to(device)\n",
        "\n",
        "patch_encoder = PatchEncoder(output_dim=128).to(device)\n",
        "model_gcn = GCNEncoder(in_dim=256, hidden_dim=256, out_dim=256).to(device)\n",
        "regression_head = RegressionHead(input_dim=256).to(device)\n",
        "contrastive_loss = MultipleContrastiveLoss(alpha=0.5, omega1=0.8, omega2=0.8, omega3=0.2)\n",
        "\n",
        "# Optimizer with weight decay\n",
        "optimizer = optim.AdamW([\n",
        "    {'params': model_anchor.parameters(), 'lr': 1e-4},\n",
        "    {'params': patch_encoder.parameters(), 'lr': 1e-4},\n",
        "    {'params': model_gcn.parameters(), 'lr': 1e-4},\n",
        "    {'params': regression_head.parameters(), 'lr': 1e-4}\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "# Learning rate schedulers - REMOVED VERBOSE PARAMETER\n",
        "scheduler_cosine = CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)\n",
        "scheduler_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 25\n",
        "best_mae = float('inf')\n",
        "patience_counter = 0\n",
        "patience_limit = 25  # Increased patience\n",
        "min_lr = 1e-7  # Minimum learning rate\n",
        "grad_clip = 0.5  # More aggressive gradient clipping\n",
        "\n",
        "# Custom learning rate scheduler\n",
        "def adjust_learning_rate(optimizer, epoch, base_lr=1e-4):\n",
        "    \"\"\"Adjust learning rate with warmup and cosine decay\"\"\"\n",
        "    # Warmup for first 10 epochs\n",
        "    if epoch < 10:\n",
        "        lr = base_lr * (epoch + 1) / 10\n",
        "    # Cosine decay to min_lr\n",
        "    else:\n",
        "        progress = (epoch - 10) / (num_epochs - 10)\n",
        "        lr = min_lr + 0.5 * (base_lr - min_lr) * (1 + math.cos(math.pi * progress))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    return lr\n",
        "\n",
        "# Additional regularization\n",
        "label_smoothing = 0.1  # For regression\n",
        "ema_decay = 0.999  # Exponential moving average\n",
        "\n",
        "# Create EMA model\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.model = model\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.backup = {}\n",
        "\n",
        "    def register(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def update(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def apply_shadow(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.backup[name] = param.data\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def restore(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data = self.backup[name]\n",
        "        self.backup = {}\n",
        "\n",
        "# Initialize EMA\n",
        "ema = EMA(model_anchor, decay=ema_decay)\n",
        "ema.register()\n",
        "\n",
        "# Enhanced train epoch\n",
        "\n",
        "def train_epoch(model_anchor, patch_encoder, model_gcn, regression_head,\n",
        "                optimizer, dataloader, device, contrastive_loss, epoch,\n",
        "                deca, deca_proj):\n",
        "\n",
        "    model_anchor.train()\n",
        "    patch_encoder.train()\n",
        "    model_gcn.train()\n",
        "    regression_head.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    # Update learning rate\n",
        "    current_lr = adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "    for img, age in dataloader:\n",
        "        img, age = img.to(device), age.to(device).float().unsqueeze(1)\n",
        "\n",
        "        anchors = []\n",
        "        positives = []\n",
        "        regression_losses = []\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Process entire batch at once\n",
        "        anchor = model_anchor(img)\n",
        "\n",
        "        # Process each image for graph construction\n",
        "        for img_tensor in img:\n",
        "            with torch.no_grad():\n",
        "                x, edge_index = patch_graph_from_image( img_tensor, patch_encoder, patch_size=32, k=8, deca=deca, deca_proj=deca_proj)\n",
        "            h_positive = model_gcn(x, edge_index).mean(dim=0, keepdim=True)\n",
        "            positives.append(h_positive)\n",
        "\n",
        "        positive = torch.cat(positives, dim=0)\n",
        "        reg_pred = regression_head(anchor)\n",
        "\n",
        "        # Label smoothing for regression\n",
        "        reg_loss = F.smooth_l1_loss(reg_pred, age)\n",
        "        reg_loss = (1 - label_smoothing) * reg_loss + label_smoothing * F.l1_loss(reg_pred, age)\n",
        "\n",
        "        # Create negative samples by shuffling the batch\n",
        "        negative = anchor[torch.randperm(anchor.size(0))]\n",
        "\n",
        "        # Normalize features for contrastive loss\n",
        "        anchor_norm = F.normalize(anchor, dim=1)\n",
        "        positive_norm = F.normalize(positive, dim=1)\n",
        "        negative_norm = F.normalize(negative, dim=1)\n",
        "\n",
        "        con_loss = contrastive_loss(anchor_norm, positive_norm, negative_norm, positive_norm)\n",
        "        loss = reg_loss + 0.1 * con_loss  # Reduced contrastive weight\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model_anchor.parameters(), max_norm=grad_clip)\n",
        "        torch.nn.utils.clip_grad_norm_(patch_encoder.parameters(), max_norm=grad_clip)\n",
        "        torch.nn.utils.clip_grad_norm_(model_gcn.parameters(), max_norm=grad_clip)\n",
        "        torch.nn.utils.clip_grad_norm_(regression_head.parameters(), max_norm=grad_clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update EMA model\n",
        "        ema.update()\n",
        "\n",
        "        total_loss += loss.item() * img.size(0)\n",
        "\n",
        "    return total_loss / len(dataloader.dataset), current_lr\n",
        "\n",
        "\n",
        "# ==================== TRACKERS FOR VISUALIZATION ====================\n",
        "train_loss_list = []\n",
        "valid_mae_list = []\n",
        "valid_cs_list = []\n",
        "lr_list = []\n",
        "epoch_times = []\n",
        "\n",
        "# ==================== MAIN TRAINING LOOP ====================\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss, current_lr = train_epoch(\n",
        "        model_anchor,\n",
        "        patch_encoder,\n",
        "        model_gcn,\n",
        "        regression_head,\n",
        "        optimizer,\n",
        "        train_loader,\n",
        "        device,\n",
        "        contrastive_loss,\n",
        "        epoch,\n",
        "        deca=model_anchor.deca,\n",
        "        deca_proj=model_anchor.deca_proj\n",
        "    )\n",
        "\n",
        "    # Evaluate with EMA model\n",
        "    ema.apply_shadow()\n",
        "    val_mae, val_cs = evaluate(model_anchor, regression_head, val_loader, device, tau=5)\n",
        "    ema.restore()\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    # Save metrics for visualization\n",
        "    train_loss_list.append(train_loss)\n",
        "    valid_mae_list.append(val_mae)\n",
        "    valid_cs_list.append(val_cs)\n",
        "    lr_list.append(current_lr)\n",
        "    epoch_times.append(epoch_time)\n",
        "\n",
        "    # Console log\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Time: {epoch_time:.1f}s | LR: {current_lr:.2e}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val MAE: {val_mae:.4f} | CS(5): {val_cs:.2f}%\")\n",
        "\n",
        "    # Early stopping and model checkpoint\n",
        "    if val_mae < best_mae:\n",
        "        best_mae = val_mae\n",
        "        patience_counter = 0\n",
        "        torch.save({\n",
        "            'model_anchor': model_anchor.state_dict(),\n",
        "            'patch_encoder': patch_encoder.state_dict(),\n",
        "            'model_gcn': model_gcn.state_dict(),\n",
        "            'regression_head': regression_head.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'epoch': epoch,\n",
        "            'val_mae': val_mae,\n",
        "            'val_cs': val_cs\n",
        "        }, 'best_model.pth')\n",
        "        print(f\"✅ New best model saved with MAE: {val_mae:.4f}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience_limit:\n",
        "            print(f\"⏹ Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "\n",
        "# # ==================== MAIN TRAINING LOOP ====================\n",
        "# for epoch in range(num_epochs):\n",
        "#     start_time = time.time()\n",
        "#     train_loss, current_lr = train_epoch(\n",
        "#         model_anchor,\n",
        "#         patch_encoder,\n",
        "#         model_gcn,\n",
        "#         regression_head,\n",
        "#         optimizer,\n",
        "#         train_loader,\n",
        "#         device,\n",
        "#         contrastive_loss,\n",
        "#         epoch,\n",
        "#         deca=model_anchor.deca,\n",
        "#         deca_proj=model_anchor.deca_proj\n",
        "#     )\n",
        "\n",
        "\n",
        "\n",
        "#     # Evaluate with EMA model\n",
        "#     ema.apply_shadow()\n",
        "#     val_mae, val_cs = evaluate(model_anchor, regression_head, val_loader, device, tau=5)\n",
        "#     ema.restore()\n",
        "\n",
        "#     epoch_time = time.time() - start_time\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}/{num_epochs} | Time: {epoch_time:.1f}s | LR: {current_lr:.2e}\")\n",
        "#     print(f\"Train Loss: {train_loss:.4f} | Val MAE: {val_mae:.4f} | CS(5): {val_cs:.2f}%\")\n",
        "\n",
        "#     # Early stopping and model checkpoint\n",
        "#     if val_mae < best_mae:\n",
        "#         best_mae = val_mae\n",
        "#         patience_counter = 0\n",
        "#         torch.save({\n",
        "#             'model_anchor': model_anchor.state_dict(),\n",
        "#             'patch_encoder': patch_encoder.state_dict(),\n",
        "#             'model_gcn': model_gcn.state_dict(),\n",
        "#             'regression_head': regression_head.state_dict(),\n",
        "#             'optimizer': optimizer.state_dict(),\n",
        "#             'epoch': epoch,\n",
        "#             'val_mae': val_mae,\n",
        "#             'val_cs': val_cs\n",
        "#         }, 'best_model.pth')\n",
        "#         print(f\"New best model saved with MAE: {val_mae:.4f}\")\n",
        "#     else:\n",
        "#         patience_counter += 1\n",
        "#         if patience_counter >= patience_limit:\n",
        "#             print(f\"Early stopping at epoch {epoch+1}\")\n",
        "#             break\n",
        "\n",
        "# Load best model for final evaluation\n",
        "try:\n",
        "    checkpoint = torch.load('best_model.pth', weights_only=False)\n",
        "except:\n",
        "    # Handle weight loading issues\n",
        "    import numpy\n",
        "    from torch.serialization import safe_globals\n",
        "    safe_globals.add(numpy.core.multiarray.scalar)\n",
        "    checkpoint = torch.load('best_model.pth', weights_only=True)\n",
        "\n",
        "model_anchor.load_state_dict(checkpoint['model_anchor'])\n",
        "regression_head.load_state_dict(checkpoint['regression_head'])\n",
        "final_mae, final_cs = evaluate(model_anchor, regression_head, val_loader, device)\n",
        "print(f\"Final Evaluation | MAE: {final_mae:.4f} | CS(5): {final_cs:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T14:09:32.169369Z",
          "iopub.execute_input": "2025-09-23T14:09:32.169675Z",
          "iopub.status.idle": "2025-09-24T00:48:42.08607Z",
          "shell.execute_reply.started": "2025-09-23T14:09:32.169642Z",
          "shell.execute_reply": "2025-09-24T00:48:42.085268Z"
        },
        "id": "98aL7VY_aFY5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14,7))\n",
        "\n",
        "# Components (box label, (x,y))\n",
        "boxes = [\n",
        "    (\"Input Image\", (0.02, 0.55)),\n",
        "    (\"DECA 3D\\n(Geometry/Expression/Pose)\", (0.25, 0.75)),\n",
        "    (\"ResNet-50\\n(Global Features)\", (0.25, 0.55)),\n",
        "    (\"VGG16\\n(Spatial Features)\", (0.25, 0.35)),\n",
        "    (\"Anchor Encoder\\n(Fusion of ResNet + VGG + DECA)\", (0.5, 0.55)),\n",
        "    (\"Patch Encoder\\n(Local Patch Features)\", (0.5, 0.25)),\n",
        "    (\"Graph Conv Net\\n(GCN over Patches)\", (0.72, 0.4)),\n",
        "    (\"Fusion + Regression\\nHead\", (0.88, 0.55)),\n",
        "    (\"Predicted Age\", (1.05, 0.55))\n",
        "]\n",
        "\n",
        "# Draw boxes\n",
        "for text, (x,y) in boxes:\n",
        "    ax.add_patch(mpatches.FancyBboxPatch(\n",
        "        (x,y), 0.18, 0.15, boxstyle=\"round,pad=0.02\",\n",
        "        fc=\"lightblue\", ec=\"black\", lw=1.5\n",
        "    ))\n",
        "    ax.text(x+0.09, y+0.075, text, ha=\"center\", va=\"center\",\n",
        "            fontsize=9, weight=\"bold\")\n",
        "\n",
        "# Arrows between modules\n",
        "arrow_pairs = [\n",
        "    (0.20,0.625,0.25,0.625),   # input → DECA\n",
        "    (0.20,0.625,0.25,0.585),   # input → ResNet\n",
        "    (0.20,0.625,0.25,0.385),   # input → VGG\n",
        "\n",
        "    (0.43,0.8,0.50,0.625),     # DECA → AnchorEncoder\n",
        "    (0.43,0.625,0.50,0.625),   # ResNet → AnchorEncoder\n",
        "    (0.43,0.385,0.50,0.625),   # VGG → AnchorEncoder\n",
        "\n",
        "    (0.43,0.385,0.50,0.275),   # VGG also → PatchEncoder\n",
        "    (0.50,0.325,0.72,0.45),    # PatchEncoder → GCN\n",
        "\n",
        "    (0.58,0.625,0.88,0.625),   # AnchorEncoder → Fusion+Reg\n",
        "    (0.78,0.45,0.88,0.625),    # GCN → Fusion+Reg\n",
        "    (1.06,0.625,1.05,0.625)    # Final → Prediction\n",
        "]\n",
        "\n",
        "for x1,y1,x2,y2 in arrow_pairs:\n",
        "    ax.annotate(\"\", xy=(x2,y2), xytext=(x1,y1),\n",
        "                arrowprops=dict(arrowstyle=\"->\", lw=2, color=\"black\"))\n",
        "\n",
        "ax.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-24T00:48:42.086999Z",
          "iopub.execute_input": "2025-09-24T00:48:42.087323Z",
          "iopub.status.idle": "2025-09-24T00:48:42.341608Z",
          "shell.execute_reply.started": "2025-09-24T00:48:42.087297Z",
          "shell.execute_reply": "2025-09-24T00:48:42.340866Z"
        },
        "id": "CZfXKHzOaFY6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Switch to eval mode\n",
        "model_anchor.eval()\n",
        "regression_head.eval()\n",
        "\n",
        "# Pick a few samples from validation set\n",
        "num_samples = 8\n",
        "samples = random.sample(range(len(val_dataset)), num_samples)\n",
        "\n",
        "fig, axes = plt.subplots(2, num_samples//2, figsize=(18, 6))\n",
        "\n",
        "for i, idx in enumerate(samples):\n",
        "    img, true_age = val_dataset[idx]\n",
        "    img_tensor = img.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        anchor = model_anchor(img_tensor)\n",
        "        pred_age = regression_head(anchor).item()\n",
        "\n",
        "    # Convert tensor to image\n",
        "    img_display = TF.to_pil_image(img)\n",
        "\n",
        "    ax = axes[i // (num_samples//2), i % (num_samples//2)]\n",
        "    ax.imshow(img_display)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(f\"True: {true_age:.0f}\\nPred: {pred_age:.1f}\", fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-24T00:48:42.342482Z",
          "iopub.execute_input": "2025-09-24T00:48:42.342753Z",
          "iopub.status.idle": "2025-09-24T00:48:43.683121Z",
          "shell.execute_reply.started": "2025-09-24T00:48:42.342728Z",
          "shell.execute_reply": "2025-09-24T00:48:43.68234Z"
        },
        "id": "QdNyz05paFY6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "model_anchor.eval()\n",
        "regression_head.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img, age in val_loader:\n",
        "        img = img.to(device)\n",
        "        age = age.cpu().numpy()\n",
        "\n",
        "        pred = regression_head(model_anchor(img)).cpu().numpy()\n",
        "\n",
        "        y_true.extend(age)\n",
        "        y_pred.extend(pred)\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.scatter(y_true, y_pred, alpha=0.5, edgecolors=\"k\")\n",
        "plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], \"r--\", lw=2)\n",
        "plt.xlabel(\"True Age\", fontsize=12)\n",
        "plt.ylabel(\"Predicted Age\", fontsize=12)\n",
        "plt.title(\"True vs Predicted Ages\", fontsize=14)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-24T00:48:43.684085Z",
          "iopub.execute_input": "2025-09-24T00:48:43.684323Z",
          "iopub.status.idle": "2025-09-24T00:49:51.122562Z",
          "shell.execute_reply.started": "2025-09-24T00:48:43.684305Z",
          "shell.execute_reply": "2025-09-24T00:49:51.121808Z"
        },
        "id": "7H7mwuMkaFY7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "# Example: 9 patches → graph\n",
        "G = nx.grid_2d_graph(3,3)\n",
        "pos = {(x,y):(x,y) for x,y in G.nodes()}\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "nx.draw(G, pos, with_labels=False, node_color=\"skyblue\", node_size=800, edge_color=\"gray\")\n",
        "plt.title(\"Patch-level Graph Construction\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-24T02:10:44.940132Z",
          "iopub.execute_input": "2025-09-24T02:10:44.940575Z",
          "iopub.status.idle": "2025-09-24T02:10:46.233117Z",
          "shell.execute_reply.started": "2025-09-24T02:10:44.940538Z",
          "shell.execute_reply": "2025-09-24T02:10:46.232071Z"
        },
        "id": "jUiKcg2oaFY7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "0kIyjFNpaFY7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Suppose you collected these during training\n",
        "train_losses = []   # append(train_loss) inside loop\n",
        "val_maes = []       # append(val_mae) inside loop\n",
        "val_cs5 = []        # append(val_cs) inside loop\n",
        "\n",
        "# Plot\n",
        "fig, ax1 = plt.subplots(figsize=(8,5))\n",
        "\n",
        "ax1.plot(train_losses, label=\"Train Loss\", color=\"blue\")\n",
        "ax1.set_ylabel(\"Loss\", color=\"blue\")\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(val_maes, label=\"Val MAE\", color=\"red\")\n",
        "ax2.set_ylabel(\"MAE\", color=\"red\")\n",
        "\n",
        "plt.title(\"Training Loss & Validation MAE over Epochs\")\n",
        "plt.show()\n",
        "\n",
        "# CS(5) accuracy curve\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(val_cs5, marker=\"o\", color=\"green\")\n",
        "plt.title(\"Validation CS(5) across Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"CS(5) %\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-24T02:20:48.360863Z",
          "iopub.execute_input": "2025-09-24T02:20:48.361182Z",
          "iopub.status.idle": "2025-09-24T02:20:48.827257Z",
          "shell.execute_reply.started": "2025-09-24T02:20:48.36116Z",
          "shell.execute_reply": "2025-09-24T02:20:48.825846Z"
        },
        "id": "tUAUuLtdaFY7"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}